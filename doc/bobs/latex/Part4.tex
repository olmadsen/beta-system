\part{} 
\section{{\bf Summary of terminology}}
In this section we shall give a short summary of the notion of a
context--free grammar, some parsing terminology, and an
introduction to LR--parser construction.
For a more detailed and explanatory treatment see Aho \&
Ullman [20].

Let $M$ be a set of symbols, then $M^*$ denotes the set of
{\bf all} strings of symbols from $M$, furthermore it
includes the empty string (denoted by e).

\begin{eksempel}
\mbox{}
\end{eksempel}
Let $A = \{0,1\}$, then
\begin{center}
$A^* = \{e,0,1,00,01,10,11,000,001,\ldots\}$
\end{center}
\kas

\subsection{Context free grammar}

A {\bf context--free grammar} (CFG) is a 4-tuple $G =
(N,\;\Sigma,\;P,\;S)$, where
\begin{enumerate}
\item $N$ is a finite set of {\bf nonterminal symbols}.
\item $\Sigma$ is a finite set of {\bf terminal symbols}.
\item $P$ is a finite set of {\bf productions} each on the
form:
\begin{center}
$ A \rightarrow \;\alpha$
\end{center}
where $A$ is in $N$ and $\alpha$ is in $(N \; \cup \; \Sigma)^*$.
\item $S$ is a distinguished symbol in $N$ called the
{\bf start symbol} (or goal symbol).\hfill $\Box$
\end{enumerate}


A {\bf sentential form} of a grammar $G$ is defined
recursively as follows:
\begin{enumerate}
\item $S$ is a sentential form.
\item If ${\bf \alpha} \; B \;\gamma$ is a sentential form, and $B\;
\rightarrow\; {\bf \delta}$ is a production in $P$, then
${\bf \alpha\; \delta} \;\gamma$ is a sentential form.
We say that ${\bf \alpha} \; B \;\gamma$ {\bf directly derives} 
${\bf \alpha\; \delta} \;\gamma$ and denote this by:
\begin{center}
${\bf \alpha} \;B\; \gamma \;\Rightarrow \;{\bf \alpha} \;\delta
\;\gamma$ \end{center}
\end{enumerate}
\kas
A sentential form containing no nonterminals is called a {\bf 
sentence} generated by $G$.

The {\bf language generated by a grammar} $G$, denoted
$L(G)$, is the set of sentences generated by $G$. I.e. \ a grammar
$G$ defines a language of strings of its terminal symbols.
\kas

We use the following conventions

\begin{tabbing}
xxxxx \= A, B, C, $\cdots$ xxxxxx\= \kill
\> $\alpha, \;\beta, \;\gamma, \;\delta, \;\ldots$ \> are in
$(N \;\cup \; \Sigma)^*$\\
\>$ a,\; b,\; c, \;d, \;\ldots$ \>  are in  $\Sigma$\\
\>$ v,\; x,\; y, \;z,\; w, \;\ldots$ \> are in $\Sigma^*$\\
\>$ A,\; B, \;C,\; \ldots$ \> are in $N$
\end{tabbing}

Let ${\bf \alpha}, \;\beta$ be sentential forms.
We say that $\alpha$ {\bf derives} $\beta$ and denote it by
$\alpha \;\Rightarrow ^*\; \beta$ if and only if:

\begin{quote}
$\alpha = \beta$ \mbox{or}\\
\mbox{there exist sentential forms}\\
$\gamma_0, \gamma_1, \ldots, \gamma_n , \;n \geq 1$
\mbox{and}\\
$ \alpha = \gamma_0, \beta = \gamma_n$, \mbox{such that}\\
$\gamma_0 \;\Rightarrow_1\gamma_n$,\\
$\gamma_1 \; \Rightarrow \;\gamma_{2}$,\\
\hspace*{5mm}$\vdots$\\
$\gamma_{n-1} \; \Rightarrow \;\gamma_n.$
\end{quote}

The sequence:
\begin{center}
$\gamma_0 \;\Rightarrow \;\gamma_1 \; \Rightarrow \;\gamma_2
\Rightarrow \;\ldots \;\gamma_{n-1} \;\Rightarrow \;\gamma_n$\\
\end{center}
is called a {\bf derivation} of $\beta$ from ${\bf \alpha}$.

A derivation is called a {\bf rightmost derivation} if, in
each step $\gamma_i \; \Rightarrow \; \gamma_{i+1}$, it is 
always the
rightmost nonterminal in $\gamma_i$ which is replaced by means of a
production. 
The symbols $\Rightarrow_{rm}\;\; \Rightarrow^*_{rm}$, indicate
rightmost derivations.

A nonterminal $E$ is called {\bf left recursive} if and
only if $E \;\Rightarrow \;\alpha \;\Rightarrow ^*\; E \;\alpha'$ for
some $\alpha,\;\alpha'$. {\bf Right recursive} is defined in a
similar way. \kas
A grammar $G$ is {\bf ambiguous} if and only if some sentence $w$
in $L(G)$ has more than one distinct rightmost derivation.\kas

\begin{eksempel}
\mbox{}
\end{eksempel}
Consider the grammar 
\begin{center}
$G_{0} = (\{E,T,P\},\{+,*,(,),a\},\cal{P},E),$
\end{center}

where $\cal{P}$ consists of\\
\begin{eqnarray*}
E & \rightarrow & E + T\\
E & \rightarrow & T\\
T & \rightarrow & T\ast P\\
T & \rightarrow & P\\
P & \rightarrow & (E)\\
P & \rightarrow & a
\end{eqnarray*}

An example of a rightmost derivation in $G_0$ is:


\begin{tabbing}
\hspace{1cm} \=  $E$n \= n$\Rightarrow_{rm}$n \= $E + T$ \= $\ast$
\=  \kill \> $E$\> $\Rightarrow_{rm}$ \>  $E + T$\\
\>\> $\Rightarrow_{rm}$ \> $E + T$ \> $\ast$ \> $P$\\
\> \>$\Rightarrow_{rm}$ \> $E + T$ \> $\ast$ \> $a$\\
\>\> $\Rightarrow_{rm}$ \> $E + P$ \> $\ast$ \> $a$\\
\>\> $\Rightarrow_{rm}$ \> $E + a$ \> $\ast$ \> $a$\\
\>\> $\Rightarrow_{rm}$ \> $T + a$ \> $\ast$ \> $a$\\
\>\> $\Rightarrow_{rm}$ \> $P + a$ \> $ \ast$ \> $a$\\
\> \>$\Rightarrow_{rm}$ \> $a + a$ \> $\ast$ \> $a$
\end{tabbing} \kas

\subsection{Parser and parser-generator}
A {\bf parser} for a grammar $G$ is a device which, given a
string $w$ in $\Sigma^*$, checks whether this string in in $L(G)$
and, if so, outputs a possible derivation of $w$ from $S$.
Note that a string may have more than one derivation. \kas

A {\bf parser-generator} is a device which, given a grammar
$G$ as input, produces a parser for $G$.

In practice a parser-generator will only accept a restricted class
of grammars.
A general system would be quite inefficient and not useable for
practical purposes.
At present the biggest and most natural class of grammars for which
useable parser-generators/parsers can be constructed is the class
of LR-grammars (in particular LALR(1)).
We note that an ambiguous grammar is not an LR-grammar. \kas

\subsection{LR(k) grammar}
An LR-parser works by constructing a rightmost derivation backwards.
The output of the parser is the reversed sequence of productions
used in the rightmost derivation of the input string.
This reversed sequence of productions is called a {\bf right
parse}.
A sentential form is in the following always a rightmost sentential
form.

If $S \;\Rightarrow^*_{rm}\; \alpha \;A \;w \Rightarrow \;\alpha
\;\beta \;w \;\Rightarrow^*_{rm} x \;w, \mbox{where}
x, \; w \;\in \;\Sigma^*, \mbox{then} \;\alpha \;\beta \;w$ is
a rightmost sentential form which may appear during a parse of
$x \;w$. $\beta$ is called the {\bf handle} of
$\alpha \beta w$, and $A \rightarrow \beta$ is called the {\bf
handle production}.
Given a sentential form, the purpose of the parser is to determine
the handle production.

In general the whole sentential form must be available in order to
determine the handle production.
This is not desirable in practice as the input string may be very
long.
An LR(k) grammar has the property that the handle production of
each sentential form can be uniquely determined by scanning the
sentential form from \underline{L}eft to right, producing a
\underline{R}ight parse, but only looking ahead at most
\underline{k}--symbols beyond the right end of the handle.

Let $G$ be an LR(k) grammar and let $\alpha\;\beta\;w$ be a
sentential form with handle production $A \rightarrow \beta$.
If $\alpha\;\beta\;y$ is another sentential
form, and if the first k symbols of $w$ are identical with the
first k symbols of $Y$, then $A \rightarrow \beta$ must also be
the handle production of $\alpha \; \beta \; y$.

This may be formalized in the following definitions:

{\bf Definition}\\
Let $G = (\Sigma, N, P, S),\; \mbox{and}\; \alpha \in (N \cup
\Sigma)^*$, then\\
\begin{center}
$FIRST_k (\alpha) = \{x \in \Sigma^* \mid \alpha 
\Rightarrow^* x w |x | = k \;\mbox{or}\;
\alpha \Rightarrow ^* x, | x | < k\}$
\end{center}
$|x|$ is the length of the string $x, |e
| = 0$ \kas

{\bf Definition}\\
Let $G = (N, \Sigma, P, S)$ be a CFG. Let $G' = (N \cup
\{S'\}, \Sigma, P \cup \{S' \rightarrow S\}, S')$ be its
{\bf augmented grammar}. {\bf G is LR(k)}, $k \geq 0$,
if the three conditions 
\begin{enumerate}
\item $S'\; \Rightarrow^*_{rm} \;\alpha\;  A w \;\Rightarrow\,
\alpha\; \beta \;w$, 
\item $S' \Rightarrow ^*_{rm} \gamma B x
\Rightarrow \gamma \delta x = \alpha \beta y,$ and
\item $FIRST_k (w) = FIRST_k(y)$,
\end{enumerate}

imply that $\alpha = \gamma, A = B$, and $x = y$ \kas

There are various technical reasons for using a new start symbol
$S'$, and a new production $S' \rightarrow S$. 
See Aho and Ullman [20].

\subsubsection{Shift--reduce parser}
In the following we shall only consider LR(1) grammars.
An LR-parser belongs to a class of parsers which all work in a
similar way.
Below we describe these parsers.

The parser uses a stack called the {\bf parse stack}.

It works as follows:\\
Initially the stack is empty and input consists of the string $w$.
\begin{tabbing}
\hspace{1cm}\= \hspace{5cm}\=\kill
\> stack \> input\\
\>\ramme[2cm]{\mbox{}}\> $w$
\end{tabbing}

Let $w$ be divided into $x a y$ with $x, y$ in
$\Sigma^*$, and $a$ in $\Sigma$.
At a given point during the parse the $x$ part has been read
and processed and the remainder of the input is $ay$.
The parse stack will then contain a string $ \alpha$ in $(N
\cup \Sigma)^*$, such that

\[\alpha\; a \; y \; \Rightarrow ^* w\]

and such that ${\bf \alpha}\;a\;y$ is a sentential form in the right
most derivation of $w$ from $S$.
Productions used in reducing $x$ to $\alpha$ have
been outputted.
The situation is:
\begin{tabbing}
\hspace{1cm} \= \hspace{5cm} \= \kill
\>stack \>input \\
\> \ramme[2cm][l]{$\alpha$}\> $ay$
\end{tabbing}

The parser determines its next step on the basis of $\alpha$ and
$a$ (i.e. not using information about $y$).
There are four different cases:
\begin{itemize}
\item shift: read $a$ and shift in onto the stack.
\begin{tabbing}
\hspace{1cm} \=
\hspace{5cm} \= \kill
\>stack \>input \\
\> \ramme[2cm][l]{$\alpha\;a$}\> $y$
\end{tabbing}
\item reduce: perform a reduction, that is 
$\alpha\;a\;y$ has the form 
$\gamma \delta a y$ and $B \rightarrow
\delta$ is a production and $\gamma B a y \Rightarrow_{rm} \gamma
\delta a y$ is a step in the rightmost derivation of $w$ from $S$.
The production $B \rightarrow \delta$ is outputted, and the
situation is:

\begin{tabbing}
\hspace{1cm} \=
\hspace{5cm} \= \kill
\>stack\>input\\
\>\ramme[2cm][l]{$\gamma\;B$} \>$a\;y$
\end{tabbing}
\item accept: the stack only contains the start symbol $S$, and
input is empty.
\item error: none of the above cases is applicable; $w$ is not in
$L(G)$.
\end{itemize}
\kas

To summarize, the parser shifts input symbols onto the stack,
until a handle appears on top of the stack. It then performs a
reduction. If no errors occur, this process is continued until the
start symbol appears on the stack. Parsers working in this way are
called {\bf shift reduce parsers}.

\begin{eksempel}
\mbox{}
\end{eksempel}

Consider a parse of the string $a + a \ast$ a in example 7.2.

\begin{tabbing}
xxxxx \= actionxxx \=  Stackxxxxxxxxxxxxx\= Inputxxxxx \= Output
\kill 
\> {\bf Action} \> {\bf Stack} \> {\bf Input} \> {\bf Output}\\
\mbox{}\\
\> \> \ramme[3cm][l]{} \> $a+a * a$\\
\mbox{}\\
\> shift \> \ramme[3cm][l]{$a$} \> $+ a * a$\\
\mbox{}\\
\> reduce \> \ramme[3cm][l]{$P$} \> $+a * a$ \> $P \rightarrow a$\\
\mbox{}\\
\> reduce \> \ramme[3cm][l]{$T$} \> $+ a * a$ \> $T \rightarrow P$\\
\mbox{}\\
\> reduce \> \ramme[3cm][l]{$E$} \> $+ a * a$ \> $E \rightarrow T$\\
\mbox{}\\
\> shift \> \ramme[3cm][l]{$E+$} \> $a * a$\\
\mbox{}\\
\> shift \> \ramme[3cm][l]{$E+a$} \> $* a$\\
\mbox{}\\
\> reduce \> \ramme[3cm][l]{$E+P$} \> $* a$ \> $P \rightarrow a$\\
\mbox{}\\
\> reduce \> \ramme[3cm][l]{$E+T$} \> $*a$ \> $T \rightarrow P$\\
\mbox{}\\
\> shift \> \ramme[3cm][l]{$E+T \ast$} \> $A$\\
\mbox{}\\
\> shift \> \ramme[3cm][l]{$E+T \ast a$}\\
\mbox{}\\
\> reduce \> \ramme[3cm][l]{$E+T \ast P$} \> \> $P \rightarrow a$\\
\mbox{}\\
\> reduce \> \ramme[3cm][l]{$E+T$} \> \> $T \rightarrow * 
\rightarrow P$\\ \mbox{}\\
\> reduce \> \ramme[3cm][l]{$E$} \> \> $E \rightarrow E + T$\\
\mbox{}\\
\> accept
\end{tabbing}
\kas

\subsubsection{{\bf Construction of LR--parsers}}
In practice the LR--parser does not just `look at' the stack and
the next input symbol to decide what to do next. The parser keeps
track of those productions which are possible candidates for a
reduction during the parse. This is done using tables, which
specify the next move at each state of the parse. These tables are
constructed by the parser generator.

Let $A \rightarrow \beta_1 \beta_2$ be a production.
Consider the derivation 
\[ S \Rightarrow ^*_{rm} \alpha ^{Aay} \Rightarrow \alpha
\beta_1 \beta_2 ay \Rightarrow ^*_{rm} \alpha \beta_1 x a y
\Rightarrow ^*_{rm} v x a y,\]
where $a \in \Sigma, y \in \Sigma^*$ or $a = e, y = e$.

During a parse of $v x a y, \alpha \beta_1$ will appear on the
stack at some stage with $x a y$ on input. When $x$ has been reduced
to $\beta_2$, then $A \rightarrow \beta_1 \beta_2$ is the handle
production and a is the next input symbol.
In general with $\alpha \beta_1$ on the stack we know nothing about
the input. But if part of the input is reduced to $\beta_2$ and a
is the next input symbol, then $A \rightarrow \beta_1 \beta_2$ is
the handle production.
The information that $A \rightarrow \beta_1 \beta_2$ is a future
candidate for a reduction when the stack contains $\alpha \beta_1$
is remembered in the following way:

\begin{quote}
\item $\alpha \beta_1$ is called a {\bf viable prefix} and we say
that $[A \rightarrow \beta_1 \cdots \beta_2, a]$
\item is an {\bf LR(1)-item} (or just LR-item) which is {\bf
valid} for $\alpha \beta_1$.
\end{quote}

In general a viable prefix has a lot of valid LR(1)-items. The set
of valid LR(1)-items for a viable prefix $\alpha \beta_1$ is

\begin{eqnarray*} 
V_1 (\alpha \beta_1)& = & \{[B \rightarrow \delta'
\cdot \delta'', b] \mid B \rightarrow\delta' \delta''\; \mbox{is a
production, and}\\
&& S \Rightarrow^*_{rm} \gamma B z \Rightarrow
\gamma \delta' \delta'' z = \alpha \beta_1 \delta'' z,\;
\mbox{and}\\
 && b \in FIRST_1 (z) \}
\end{eqnarray*} 

For a viable prefix $\alpha \;\beta_1$, $V_1(\alpha \;\beta_1)$
contains sufficient information to decide what parsing action to
take if $\alpha \beta_1$ is on the stack.

Let $\alpha \beta_1$ be on the stack, let $x$ be the next input
symbol and let $[A \rightarrow \beta_1 \ldots \beta_2, a]$ be in
$V_1 (\alpha \beta_1)$. There are five cases, dependent on
$\beta_2$:

\begin{enumerate}
\item $\beta_2 = x \beta_2'$.\\
I.e. \ the first symbol of $\beta_2$ is identical to the input
symbol, and the parser has to do a shift. The next state of the
parse is described by $V_1 (\alpha \beta_1 x)$, and $[A
\rightarrow \beta_1 x. \beta'_2, a] \in V_1 (\alpha \beta_1
x)$.
\item $\beta_2 = y \beta'_2, y \in \Sigma, y \neq x$.\\
$A \rightarrow \beta_1 \beta_2$ is no longer a candidate for a
reduction.
\item $\beta_2 = \ B \beta'_2, B \in N$.
$A \rightarrow \beta_1 \beta_2$ is still a candidate for a
reduction, but we must first recognize a production of the form $B
\rightarrow \delta$. 
If and when part of the input has been reduced
to $B$, then the next state of the parse is described by $V_1
(\alpha \beta_1 B)$ and $[A \rightarrow \beta_1 B \ldots \beta'_2,
a] \in V_1 (\alpha \beta_1 B)$. It also follows that $\{[B
\rightarrow \ldots \delta, b] \mid B \rightarrow \delta$ is a
production and $b \in FIRST_1 (\beta'_2 a) \} \subseteq V_1
(\alpha \beta_1)$.
\item $\beta_2 = e$ (the empty string), $x = a.$\\
We may reduce by $A \rightarrow \beta_1$, and return the the state
$V (\alpha)$, with $\alpha$ on the stack and shift $A$ on the
stack. The next state to consider is then $V(\alpha A)$.
\item $\beta_2 = e, x \neq a$.\\
$A \rightarrow \beta_1$ is no longer a candidate for a reduction.
\end{enumerate}
\kas

For an LR(1) -- grammar there are no conflicts between different
items of $V_1(\alpha \beta_1)$ in deciding whether to shift or
reduce.

For a non LR(1) grammar there will exist a viable prefix $\varphi$
such that $V_1(\varphi)$ contains two items of the form

\[ [A \rightarrow \beta_1 \ldots a \beta_2, b] , [B \rightarrow
\beta \ldots, a], a \in \Sigma, \]

or two different items of the form

\[ [A \rightarrow \alpha \ldots , a] , [B \rightarrow \beta
\ldots , a], a \in \Sigma \cup \{ e \}. \]

In both cases there is a conflict on the input symbol $a. V_1
(\varphi)$ is said to be {\bf inconsistent}.
\kas

For a given set of LR-items $V_1 (\alpha)$ we define two
functions -- the {\bf parsing action function} PA, and the {\bf
successor-function} SUCC.

\subsubsection*{Definition}
Let $\alpha$ be a viable prefix of a sential form of an LR(1)
grammar $G = (N, \Sigma, P, S)$. Let $x \in \Sigma \cup
\{e\}$. 
The {\bf parsing action function}\\

\hspace*{2cm}
$PA(\vee_1 (\alpha), x)$ takes one of the values

\begin{itemize}
\item {\bf shift}, if an item $[A \rightarrow \beta_1 \ldots
x \beta_2, a] \in V_1 (\alpha)$,
\item {\bf reduce} $A \rightarrow \beta$, if an item $[A
\rightarrow \beta \ldots, x ] \in V_1 (\alpha)$,
\item {\bf accept}, if $x = e \; \mbox{and} [S' \rightarrow S
\ldots , e] \in V_1 (\alpha)$, or
\item {\bf error}, if none of the above cases are applicable.
\end{itemize}
\kas

\subsubsection*{Definition}
Let $T - V_1 (\varphi)$ be a set of LR-items for an LR(1)
grammar $G = (N, \Sigma, P, S)$. 
Let $x \in N \cup \Sigma$.$ T' = V_1 (\varphi x) = SUCC(T, x)$ 
is the set of items computed in the following way:

\begin{enumerate}
\item The {\bf basis} of $T'$ is computed by\\
If $[A \rightarrow \alpha \ldots x \beta, a]$ is in $T$,\\
then $[A \rightarrow \alpha x \ldots \beta, a]$ is in $T'$.
\item The {\bf closure} of $T'$ is computed by
   \begin{enumerate}
    \item If $[A \rightarrow \alpha \ldots B \beta, a]$ is in
     $T'$,\\
    $B \rightarrow \delta$ is in $P$ and $b \in FIRST_1 (\beta
    a)$,\\
    then $[B \rightarrow \ldots \delta, b]$ is in $T'$.
    \item Repeat step 2.1 until no more new items can be added to
				$T'$.
     \end{enumerate}
\end{enumerate}

As there are only a finite number of LR-items for a given grammar
G, it is possible to compute in advance all the sets of LR-items
which may appear during a parse.
This is in fact done by the parser generator.

The {\bf canonical collection of sets of LR-items} may be computed
by the following algorithm.

\subsubsection*{Algorithm}
Let $G = (N, \Sigma, P, S)$ be a $CFG$. Let $G' = (N \cup \{S'\},
\Sigma, P \cup \{S' \rightarrow S\}, S')$ be the augmented grammar.
The canocical collection of sets of LR-items $\cal{A}$ is computed
by \begin{enumerate}
\item Compute the initial set $A_0$ of $\cal{A}$
   \begin{enumerate}
    \item $S' \rightarrow \ldots S, e]$ is in $A_0$
     \item Compute the closure of $A_0$
     \end{enumerate}
\item Compute the succeeding sets of $\cal{A}$
    \begin{enumerate}
     \item Let $A$ be in $\cal{A}$, and $x$ in $N \cup
\Sigma$,\\
           then compute $SUCC(A, x)$ and add it to $\cal{A}$.
     \item Repeat step 2.1 until no new set can be added to
$\cal{A}$.
     \end{enumerate}
\end{enumerate}
\kas

A set of items in the canonical collection of LR(1)-items will in
the folowing be called an {\bf LR(1)-table} (or just an LR-table).
Note that  this term is not that used by Aho \& Ullman [20].

\subsubsection{LR-parsing algorithm}
We may now formulate the parsing algorithm using LR-tables.
Besides the symbols being stacked, the LR-tables will also be
stacked in order to find the next LR-table to be used after a
reduction.
If $PA(V_1 (\alpha \beta), a)$ is {\bf reduce} $A \rightarrow
\beta$, then $\alpha A$ will be the new stack content and $V_1
(\alpha A) = SUCC(V_1 (\alpha), A)$.

In general the stack contains
\vspace*{5cm}

where $T_0$ is the initial LR-table corresponding to the empty
stack and
\[ T_i = V_1 (x_1 x_2 \ldots x_i), i = 1, 2,
\ldots, n. \]

\begin{tabbing}
Algor\= be\= rep\= ca\= shiftxxxx\=beg\= xxxxx \= \kill
{\bf Algorithm} LR(1) parsing algorithm.\\
\> {\bf BEGIN}\\
\>  \>  \>  $T$ : = initial LR-table\\    
\>	 \>  \>  $x$ : = next input symbol;\\
\>  \>  \>  let the stack initially contain $T$;\\
\>  \> {\bf REPEAT}\\
\>  \>  \>  {\bf CASE} $PA(T, x)$ {\bf OF}\\
\>  \>  \> \> shift :	\> {\bf BEGIN} shift $x$ onto the stack;\\
\>  \>  \>  \>  \> \> $T := SUCC(T, x)$;\\
\>  \>  \>  \>  \> \> shift $T$ onto the stack;\\
\>  \>  \>  \>  \> \> $x$:= next input symbol\\
\>  \>  \>  \>  \> {\bf END;}\\
\>  \>  \>  \> reduce $A \,\rightarrow \;\beta$: \> \>{\bf BEGIN}
output $A \rightarrow \beta$;\\
\>  \>  \>  \>  \>  \> \>  pop 2 $\ldots | \beta |$ symbols off the
                       stack;\\
\>  \>  \>  \>  \> \> \> $T$:= LR-table on top of the stack;\\
\>  \>  \>  \>  \>  \> \>  shift $A$ onto the stack:\\
\>  \>  \>  \>  \>  \> \> $T$:= $SUCC(T,A)$\\
\>  \>  \>  \>  \>  \>\> shift $T$ onto the stack;\\
\>  \>  \>  \>  \> \> {\bf END};\\
\>  \>  \>  \>  \> accept: announce accept;\\
\>  \>  \>  \>  \> error : annonce error\\
\>  \>  \>  {\bf END CASE;}\\
\>  \>  {\bf UNTIL} accept {\bf OR} error;\\
\>  {\bf END;}
\end{tabbing}
\kas

\subsection{Practical LR-grammars.}
For large grammars it turns out that the size of the LR(1)-tables
and the amount of work required to construct them is very large.
However, if one considers a subset of the class of LR(1) grammars
then there exist techniques for constructing usable LR-parsers.
We shall consider two such methods.

In both methods one starts by constructing the sets of canonical
LR(0)-items (LR(0)-tables) for the given grammar.

An LR(0) table $T$ may be characterised in the following way, as a 
\begin{itemize}
\item {\bf shift table}, if $T$ contains no item of the form $[A
\rightarrow \beta \ldots , e]$,
\item {\bf reduce table}, if $T$ contains an item of the form $[A
\rightarrow \beta \ldots , e]$, and all other items have form $[B
\rightarrow \beta_1 \ldots C \beta_2, e]$.
\item {\bf inadequate table}, if $T$ contains either two items of
the form
\[ [A \rightarrow \beta_1 \ldots a \beta_2, e] , [ B \rightarrow
\cdots , e] \]
or two different items of the form
\[ [A \rightarrow \alpha \ldots , e] , [B \rightarrow \beta
\ldots , e]. \] 
\end{itemize}

The parsing action of a shift table and of a reduce table can be
determined independently of the next input symbol.
This is not the case with an inadequate table where there is more
than one parsing action which may be chosen.
Inadequate tables correspond to inconsistent sets of items in the
LR(1) case.
Consequently a grammar is LR(0) if and only if none if its
LR(0)-tables are inadequate.

In order to resolve these conflicts, each inadequate table is
converted to a {\bf lookahead table}.
An attempt could then be made to try to resolve the conflicts by
looking at the next input symbol.

Let $\alpha \beta$ be a viable prefix, let $T = V_0 (\alpha
\beta)$ be an inadequate LR(0)-table.
Let the item $[A \rightarrow \beta \ldots , e]$ be in $T$.
A lookahead set $LA(T,[A \rightarrow \beta \ldots , e]) \subseteq
\Sigma \cup \{e\}$ is computed.
The idea is that if, given a parse state described by $T$, it is
possible to reduce using the rule $A \rightarrow \beta$, then the
next input symbol will be in $LA(T,[A \rightarrow \beta
\ldots , e])$.
This can be expressed by

\begin{eqnarray*}
 LA(T,[A \rightarrow \beta \ldots e])  & \supseteq & \{a \mid
\alpha ' \beta w \;\mbox{is a sentential form with} \\
V_0 (\alpha '\beta) = T, a \in  FIRST_1(w)\} 
\end{eqnarray*}

Below we describe two types of LR-grammars which differ in the way
$LA$ is defined.

Having computed $LA(T,[A \rightarrow \beta \ldots , e])$, the
item $[A \rightarrow \beta  \ldots , e]$ is replaced by $\{[A
\rightarrow \beta \ldots , a] \mid a \in LA(T,[A 
\rightarrow \beta \ldots , e]\}$. 
By doing this for all items in $T$ which may lead to a reduce, it
is possible to obtain a lookahead table $T_L$ from $T$. 
The parsing conflicts to $T$ are then resolved if the parsing
action function $PA$ can be uniquely defined on $T_L$.

There exist LR(1)-grammars for which the above way of constructing
LR-tables does not work.

\subsubsection{{\bf Simple LR(1) grammars.}}
We now consider one way of defining $LA$.

\subsubsection*{Definition}
Let $T$ be an LR(0)-table.
The set of symbols for which the parsing action is shift is:

\begin{eqnarray*}
SHIFT(T) = \{ a \in \Sigma & \mid & T\; \mbox{contains an item
of the form}\\
&& [A \rightarrow \beta_1 \ldots a \beta_2 , e]\} 
\end{eqnarray*}
\kas

\subsubsection*{Definition}
Let $G = (N, \Sigma, P, S)$ be a $CFG$. Let $A \in N$, then
\[ FOLLOW_1(A) = \{ a \in \Sigma ^* \mid s \Rightarrow ^* \alpha A
w, \in FIRST_1 (w) \} \]
\kas

\subsubsection*{Definition}
Let $G = (N, \Sigma, P, S)$ be a $CFG$.
$G$ is said to be {\bf Simple LR(1)}(SLR(1)) if any inadequate
LR(0) table satisfies the following conditions
\begin{enumerate}
\item If $[A \rightarrow \beta \ldots , e ]$ is in $T$, then
\[ FOLLOW_1(A) \cap SHIFT(T) = \emptyset\]
\item If $[A \rightarrow \alpha \ldots , e ]\; \mbox{and}\; [B
\rightarrow \beta \ldots , e ]$ is in $T$, then
\[FOLLOW_1(A) \cap FOLLOW_1(B) = \emptyset\]
\end{enumerate}
\kas

If $[A \rightarrow \beta \ldots , e]$ is an item in an inadequate
table $T$, then $FOLLOW_1(A)$ may be used as $LA (T,[A \rightarrow
\beta \ldots , e])$.

We can define SLR(1) grammars independently of the LR(0) tables.
Let $G$ be an SLR(1) grammar, let $\alpha \beta w $ be a
sentential form with reduction handle $A \rightarrow \beta
\ldots$. If $\alpha \beta x$ is a sentential form and
$FIRST_1 (x)$ is in $FOLLOW_1(A)$, then $A  \rightarrow
 \beta$ must be the reduction handle for $\alpha \beta
 x$.

The lookahead sets of an SLR(1) grammar are not minimal.
This is because FOLLOW is computed independently of the given
inadequate state.

\subsubsection{Lookahead LR-grammars.}

We shall now consider the case with minimal lookahead sets.

If $T$ is an LR(1)-table, then we define
\[ CORE(T) = \{ [A \; \rightarrow\;  \alpha \;\ldots \;\beta, e ]
\mid [A \; \rightarrow \; \alpha \; \ldots \; \beta, a] \in T\; 
\mbox{for some} \; a\} \] 

If $T_0$ is an LR(0)-table for a grammar $G$,
then there exists an LR(1) table $T$ for $G$ such that $T_0 =
CORE(T)$, and vice versa.

\subsubsection*{Definition}

Let $G = (N, \Sigma, P, S)$ be a $CFG$.
Let $\cal{A}_0$ be the set of LR(0)-tables and let $\cal{A}_1$ be
the set of LR(1)-tables.
Let $T$ be in $\cal{A}_0$, and let $T$ contain an item of the form
$[A \rightarrow  \beta \ldots , e]$.
We define 
\begin{eqnarray*}
 LALR_1(T,[A \rightarrow \beta \ldots , e]) = \{a \in \Sigma &
\mid & [A\;  \rightarrow \beta \ldots , a] \in T', T' \in 
\cal{A}_1, \\
&&\mbox{and}\; CORE(T') = T\} 
\end{eqnarray*}
\kas

\subsubsection*{Definition}
Let $G = (N, \Sigma, P, S)$ be a $CFG$.
$G$ is said to be {\bf Lookahead LR(1)} (LALR(1)) if any inadequate
table $T$ satisfies the following conditions:

\begin{enumerate}
\item If $[A \; \rightarrow \; \beta \,\ldots , e] \in T$, then\\
$LALR_1(T,\{T,[A \;\rightarrow \;\beta \,\ldots , e]) \; \cap
SHIFT(T) = \emptyset$
\item If $[A \;\rightarrow \;\alpha \;\ldots , e] \;\mbox{and}/; [B
\; \rightarrow \,\beta \;\ldots , e] \in T$, then\\
$LALR_1(T,[A \;\rightarrow \;\alpha \,\ldots , e]) \;\cap
\; LALR_1(T,[B \;\rightarrow \,\beta \,\ldots , e]) = \emptyset$
\end{enumerate}
\kas

The lookahead sets $LALR_1(T,[A \rightarrow \beta \ldots , e])$
can be computed directly from the LR(0)-tables without computing
the LR(1)-tables.
An algorithm for doing this is given in [23].

It may be difficult for an unexperienced reader to distinguish
between the various types of grammars.

In practice the following rules seem to apply:

\begin{itemize}
\item It often happens that an LR(1) grammar which is not SLR(1) is
LALR(1).
\item It is not very common that a grammar which is not LALR(1) is
in fact LR(1).
Usually such a grammar is ambiguous.
\end{itemize}

We end this section with an example of an LALR(1) grammar which is
not SLR(1).

\subsubsection*{{\bf Example}}
Consider the grammar $G = (\{S', S, A\},\{a, b, c,  d, f\}, P, S')$
where $P$ consists of

\begin{tabbing}
\hspace*{3cm} \= $S'$ xx \= $\rightarrow$ \= xx \kill
\> $S'$\> $\rightarrow$ \> $S$\\
\> $S$ \>  $\rightarrow$ \> $aAd$\\
\> $S$ \> $\rightarrow$ \> $afc$\\
\> $S$ \> $\rightarrow$ \> $bAc$\\
\> $S$\>  $\rightarrow$ \> $bfd$\\
\> $A$ \> $\rightarrow$ \> $f$
\end{tabbing}

The LR(0) tables for $G$ are ($\rightarrow$ indicates the $SUCC$
function) 

\begin{quote}
$G$ is not $LR(0)$ since $T_5$ and $T_{10}$ are inadequate.\\
$G$ is not $SLR$(1) since $FOLLOW_1(A) = \{c,d\}$.\\
$G$ is $LALR(1)$ since $LALR_1(T_{5}, [A \rightarrow f \ldots
, e]) = \{d\}$\\
and $LALR_1(T_{10'}[A \rightarrow f \ldots , e]) = \{c\}$
\end{quote}
\kas





 




